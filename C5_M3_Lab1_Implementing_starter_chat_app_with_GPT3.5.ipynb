{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcIZClFYeZYm"
   },
   "source": [
    "## **Lab objective- Implementing Conversational AI system using GPT 3.5**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVgnx_INrWjp"
   },
   "source": [
    "### Installing  library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nddcF4rKeYO2",
    "outputId": "bc21d4c9-bd5a-41d5-8b68-7c7e7fbbf8ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.28.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41LcBLBMsFGJ"
   },
   "source": [
    " ### Importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PJ4QzLFVfwjS"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "YOUR_API_KEY ='OPENAI_API_KEY'\n",
    "client = OpenAI(api_key=YOUR_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbBrYlqnsR0J"
   },
   "source": [
    "### Defining a chatbot function\n",
    "\n",
    "The `chatbot_response` function uses OpenAI's API to generate chatbot responses. It submits conversation history and settings for the model and token limit to `client.chat.completions.create`, then extracts and returns the response content from the API's result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_G99uZ72oiSJ"
   },
   "outputs": [],
   "source": [
    "conversation_history=[]\n",
    "conversation_history.append({\"role\": \"system\", \"content\": \"You are a helpful assistant.\"})\n",
    "\n",
    "def chatbot_response(messages, model=\"gpt-3.5-turbo\", max_tokens=150):\n",
    "  \"\"\"\n",
    "  Generates a response from the chatbot based on the conversation history.\n",
    "  :param messages: A list of message dicts with 'role' and 'content' keys.\n",
    "  :param model: Which OpenAI model to use.\n",
    "  :param max_tokens: Maximum length of the model's response.\n",
    "  :return: The generated response from the chatbot.\n",
    "  \"\"\"\n",
    "  response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=messages,\n",
    "  max_tokens=max_tokens\n",
    "  )\n",
    "  return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoomdVMAsX7X"
   },
   "source": [
    "### User Input and output\n",
    "This script creates a continuous chat loop where it takes user input, checks for termination commands (\"exit\" or \"quit\"), and generates chatbot responses based on the ongoing conversation. \n",
    "\n",
    "If the user doesn't exit, their input is added to the conversation history, a response is generated using the chatbot_response function, and both the user input and chatbot's response are recorded for context in future interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIOlTn6PpQWA",
    "outputId": "abee3bcb-00ff-487f-baa8-4355607a4dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: hello can you help me to solve the maths problem? \n",
      "Chatbot: Of course! I'd be happy to help you with a math problem. Please go ahead and provide me with the details of the problem you need assistance with.\n",
      "You: what is cos90 + cos30 ? \n",
      "Chatbot: To solve the expression cos(90) + cos(30), we need to know the values of cosine for 90 degrees and 30 degrees.\n",
      "\n",
      "Cosine of 90 degrees is 0, and cosine of 30 degrees is sqrt(3)/2.\n",
      "\n",
      "Therefore, cos(90) + cos(30) = 0 + sqrt(3)/2 = sqrt(3)/2.\n",
      "\n",
      "So, the result of cos(90) + cos(30) is sqrt(3)/2.\n",
      "You: exit\n",
      "Exiting chat...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  user_input = input(\"You: \")\n",
    "  if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "     print(\"Exiting chat...\")\n",
    "     break\n",
    "  # Append user input to conversation history\n",
    "  conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "  # Get response from chatbot\n",
    "  response = chatbot_response(conversation_history)\n",
    "  print(\"Chatbot:\", response)\n",
    "\n",
    "  # Optionally, you can append the chatbot's response to the conversation history if needed\n",
    "  conversation_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
