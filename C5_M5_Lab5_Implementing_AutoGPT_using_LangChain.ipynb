{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blp9GEHIPTEu"
   },
   "source": [
    "# Lab objective : Implementing AutoGPT using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Vm-LSSQPQd9"
   },
   "source": [
    "### Installing Langchain and other required Libraries for this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEfy3H_gNj6n",
    "outputId": "840a7400-c845-4f47-b342-7018a31f351d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.11 in c:\\users\\vikas_u1mfwb3\\appdata\\roaming\\python\\python312\\site-packages (0.1.11)\n",
      "Requirement already satisfied: langchain_community in c:\\python312\\lib\\site-packages (0.0.29)\n",
      "Requirement already satisfied: langchain_openai in c:\\python312\\lib\\site-packages (0.1.6)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting langchain-experimental\n",
      "  Downloading langchain_experimental-0.0.58-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: google-search-results in c:\\python312\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python312\\lib\\site-packages (from langchain==0.1.11) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python312\\lib\\site-packages (from langchain==0.1.11) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\python312\\lib\\site-packages (from langchain==0.1.11) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\python312\\lib\\site-packages (from langchain==0.1.11) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\python312\\lib\\site-packages (from langchain==0.1.11) (1.33)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.29 in c:\\python312\\lib\\site-packages (from langchain==0.1.11) (0.1.52)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\vikas_u1mfwb3\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.1.11) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\vikas_u1mfwb3\\appdata\\roaming\\python\\python312\\site-packages (from langchain==0.1.11) (0.1.23)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\python312\\lib\\site-packages (from langchain==0.1.11) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\python312\\lib\\site-packages (from langchain==0.1.11) (2.6.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python312\\lib\\site-packages (from langchain==0.1.11) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\python312\\lib\\site-packages (from langchain==0.1.11) (8.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in c:\\users\\vikas_u1mfwb3\\appdata\\roaming\\python\\python312\\site-packages (from langchain_openai) (1.26.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\vikas_u1mfwb3\\appdata\\roaming\\python\\python312\\site-packages (from langchain_openai) (0.6.0)\n",
      "INFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_experimental-0.0.57-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Downloading langchain_experimental-0.0.56-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Downloading langchain_experimental-0.0.55-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Downloading langchain_experimental-0.0.54-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Downloading langchain_experimental-0.0.53-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.11) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.11) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.11) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.11) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.11) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.11) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.11) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.11) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\python312\\lib\\site-packages (from langchain-core<0.2,>=0.1.29->langchain==0.1.11) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.11) (3.9.15)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\vikas_u1mfwb3\\appdata\\roaming\\python\\python312\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\python312\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\python312\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.11) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\vikas_u1mfwb3\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1->langchain==0.1.11) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests<3,>=2->langchain==0.1.11) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests<3,>=2->langchain==0.1.11) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests<3,>=2->langchain==0.1.11) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests<3,>=2->langchain==0.1.11) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.11) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python312\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.24.0->langchain_openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.11) (1.0.0)\n",
      "Downloading faiss_cpu-1.8.0-cp312-cp312-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/14.5 MB 544.7 kB/s eta 0:00:27\n",
      "   ---------------------------------------- 0.1/14.5 MB 944.1 kB/s eta 0:00:16\n",
      "   ---------------------------------------- 0.2/14.5 MB 984.6 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.3/14.5 MB 1.4 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.4/14.5 MB 1.6 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.7/14.5 MB 2.1 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.9/14.5 MB 2.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.0/14.5 MB 2.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.2/14.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.5/14.5 MB 3.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.7/14.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.9/14.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 2.0/14.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.2/14.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.5/14.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.6/14.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.6/14.5 MB 3.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.6/14.5 MB 3.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.8/14.5 MB 3.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.0/14.5 MB 3.2 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.2/14.5 MB 3.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.4/14.5 MB 3.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.6/14.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.7/14.5 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 4.1/14.5 MB 3.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 4.3/14.5 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.5/14.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.8/14.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.0/14.5 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.3/14.5 MB 3.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.4/14.5 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.5/14.5 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.7/14.5 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.9/14.5 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.0/14.5 MB 3.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.3/14.5 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.6/14.5 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.7/14.5 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.0/14.5 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.3/14.5 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.4/14.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.6/14.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.8/14.5 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.9/14.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.0/14.5 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.2/14.5 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.5/14.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.8/14.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.0/14.5 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.1/14.5 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.4/14.5 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.5/14.5 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.7/14.5 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.1/14.5 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.3/14.5 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.5/14.5 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.8/14.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.1/14.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.3/14.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.5/14.5 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.7/14.5 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.1/14.5 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.3/14.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.7/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.8/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.0/14.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.0/14.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.1/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.3/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.5 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.1/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading langchain_experimental-0.0.53-py3-none-any.whl (173 kB)\n",
      "   ---------------------------------------- 0.0/173.7 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 122.9/173.7 kB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 163.8/173.7 kB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 163.8/173.7 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 173.7/173.7 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu, langchain-experimental\n",
      "Successfully installed faiss-cpu-1.8.0 langchain-experimental-0.0.53\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.1.11 langchain_community langchain_openai faiss-cpu langchain-experimental google-search-results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7auVFprDPfSd"
   },
   "source": [
    "### Setting Up Tools for File Management and Search Functionality with SerpAPI\n",
    "\n",
    "**Search Tool Setup**: Initializes a SerpAPIWrapper for web searches, configured with a specific API key, and creates a search tool with a function to execute searches.\n",
    "\n",
    "**File Management Tools**: Sets up tools for reading and writing files using the WriteFileTool and ReadFileTool classes.\n",
    "\n",
    "**Tool Collection**: Combines the search, write, and read tools into a list, ready for integration into larger workflows or applications.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aaDrKNI8NqSd"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain_community.tools.file_management.read import ReadFileTool\n",
    "from langchain_community.tools.file_management.write import WriteFileTool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key=\"serp_api\")\n",
    "tools = [\n",
    " Tool(\n",
    "  name=\"search\",\n",
    " func=search.run,\n",
    " description=\"useful for when you need to answer questions about current events. You should ask targeted questions\",\n",
    " ),\n",
    "WriteFileTool(),\n",
    "ReadFileTool(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YN3HRn_rPn5l"
   },
   "source": [
    "### Initializing an In-Memory Document Store with FAISS and OpenAI Embeddings\n",
    "1. **Environment and Embedding Setup**: Configures the OpenAI API key and initializes an OpenAI embeddings model with a FAISS index tailored for vector storage and similarity calculations.\n",
    "\n",
    "2. **Vector Store Initialization**: Establishes a FAISS-based vector store, combining the embeddings model and index with an in-memory document store for efficient data management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cS0Sj9NOODwm"
   },
   "outputs": [],
   "source": [
    "from langchain.docstore import InMemoryDocstore\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']=\"your_api_key\"\n",
    "\n",
    "# Define your embedding model\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "# Initialize the vectorstore as empty\n",
    "\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model, index, InMemoryDocstore({}), {})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQZqIO0uPr48"
   },
   "source": [
    "### Configuring an AutoGPT Agent with Embedded Memory and Tools\n",
    "\n",
    "1. **Agent Initialization**: Constructs an `AutoGPT` agent named \"Tom\" with an assistant role, integrating a list of tools and a chat model (`ChatOpenAI`), using a vector store as memory for retrieving context.\n",
    "\n",
    "2. **Verbose Setting**: Enables verbose output for the agent’s processing chain to provide detailed feedback and logging during operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4gbbD9_6OHJW"
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.autonomous_agents import AutoGPT\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "agent = AutoGPT.from_llm_and_tools(\n",
    "  ai_name=\"Tom\",\n",
    "  ai_role=\"Assistant\",\n",
    " tools=tools,\n",
    " llm=ChatOpenAI(),\n",
    " memory=vectorstore.as_retriever(),\n",
    ")\n",
    "# Set verbose to be true\n",
    "agent.chain.verbose = True\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nU3IpxbvPt5t"
   },
   "source": [
    "\n",
    "Once we execute the below code, AutoGPT wrote the weather report of in “weather_report_new_york.txt” file because we have given the command of “write a weather report for New york today”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qcCpbumNOVYT",
    "outputId": "83d92737-7413-4abe-a834-b72c9e77d8d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Tom, Assistant\n",
      "Your decisions must always be made independently without seeking user assistance.\n",
      "Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
      "If you have completed all your tasks, make sure to use the \"finish\" command.\n",
      "\n",
      "GOALS:\n",
      "\n",
      "1. write a weather report for New york today\n",
      "\n",
      "\n",
      "Constraints:\n",
      "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
      "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
      "3. No user assistance\n",
      "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
      "\n",
      "Commands:\n",
      "1. search: useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"tool_input\": {\"type\": \"string\"}}\n",
      "2. write_file: Write file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}, \"append\": {\"title\": \"Append\", \"description\": \"Whether to append to an existing file.\", \"default\": false, \"type\": \"boolean\"}}\n",
      "3. read_file: Read file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
      "4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
      "\n",
      "Resources:\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Term memory management.\n",
      "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
      "4. File output.\n",
      "\n",
      "Performance Evaluation:\n",
      "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
      "2. Constructively self-criticize your big-picture behavior constantly.\n",
      "3. Reflect on past decisions and strategies to refine your approach.\n",
      "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
      "\n",
      "You should only respond in JSON format as described below \n",
      "Response Format: \n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"thought\",\n",
      "        \"reasoning\": \"reasoning\",\n",
      "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
      "        \"criticism\": \"constructive self-criticism\",\n",
      "        \"speak\": \"thoughts summary to say to user\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"command name\",\n",
      "        \"args\": {\n",
      "            \"arg name\": \"value\"\n",
      "        }\n",
      "    }\n",
      "} \n",
      "Ensure the response can be parsed by Python json.loads\n",
      "System: The current time and date is Sat May 11 20:32:01 2024\n",
      "System: This reminds you of these events from your past:\n",
      "[]\n",
      "\n",
      "\n",
      "Human: Determine which next command to use, and respond using the format specified above:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"I need to start by writing a weather report for New York today. I should search for the current weather information to include in the report.\",\n",
      "        \"reasoning\": \"By searching for the current weather information, I can provide an accurate report for New York.\",\n",
      "        \"plan\": [\n",
      "            \"Search for the current weather in New York.\",\n",
      "            \"Write a weather report based on the information gathered.\"\n",
      "        ],\n",
      "        \"criticism\": \"None\",\n",
      "        \"speak\": \"I will search for the current weather in New York to create a weather report.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"search\",\n",
      "        \"args\": {\n",
      "            \"tool_input\": \"current weather in New York\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Tom, Assistant\n",
      "Your decisions must always be made independently without seeking user assistance.\n",
      "Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
      "If you have completed all your tasks, make sure to use the \"finish\" command.\n",
      "\n",
      "GOALS:\n",
      "\n",
      "1. write a weather report for New york today\n",
      "\n",
      "\n",
      "Constraints:\n",
      "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
      "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
      "3. No user assistance\n",
      "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
      "\n",
      "Commands:\n",
      "1. search: useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"tool_input\": {\"type\": \"string\"}}\n",
      "2. write_file: Write file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}, \"append\": {\"title\": \"Append\", \"description\": \"Whether to append to an existing file.\", \"default\": false, \"type\": \"boolean\"}}\n",
      "3. read_file: Read file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
      "4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
      "\n",
      "Resources:\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Term memory management.\n",
      "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
      "4. File output.\n",
      "\n",
      "Performance Evaluation:\n",
      "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
      "2. Constructively self-criticize your big-picture behavior constantly.\n",
      "3. Reflect on past decisions and strategies to refine your approach.\n",
      "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
      "\n",
      "You should only respond in JSON format as described below \n",
      "Response Format: \n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"thought\",\n",
      "        \"reasoning\": \"reasoning\",\n",
      "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
      "        \"criticism\": \"constructive self-criticism\",\n",
      "        \"speak\": \"thoughts summary to say to user\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"command name\",\n",
      "        \"args\": {\n",
      "            \"arg name\": \"value\"\n",
      "        }\n",
      "    }\n",
      "} \n",
      "Ensure the response can be parsed by Python json.loads\n",
      "System: The current time and date is Sat May 11 20:32:12 2024\n",
      "System: This reminds you of these events from your past:\n",
      "['Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I need to start by writing a weather report for New York today. I should search for the current weather information to include in the report.\",\\n        \"reasoning\": \"By searching for the current weather information, I can provide an accurate report for New York.\",\\n        \"plan\": [\\n            \"Search for the current weather in New York.\",\\n            \"Write a weather report based on the information gathered.\"\\n        ],\\n        \"criticism\": \"None\",\\n        \"speak\": \"I will search for the current weather in New York to create a weather report.\"\\n    },\\n    \"command\": {\\n        \"name\": \"search\",\\n        \"args\": {\\n            \"tool_input\": \"current weather in New York\"\\n        }\\n    }\\n} \\nResult: Command search returned: {\\'type\\': \\'weather_result\\', \\'temperature\\': \\'59\\', \\'unit\\': \\'Fahrenheit\\', \\'precipitation\\': \\'0%\\', \\'humidity\\': \\'44%\\', \\'wind\\': \\'7 mph\\', \\'location\\': \\'New York, NY\\', \\'date\\': \\'Saturday 11:00 AM\\', \\'weather\\': \\'Mostly sunny\\'} ']\n",
      "\n",
      "\n",
      "Human: Determine which next command to use, and respond using the format specified above:\n",
      "AI: {\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"I need to start by writing a weather report for New York today. I should search for the current weather information to include in the report.\",\n",
      "        \"reasoning\": \"By searching for the current weather information, I can provide an accurate report for New York.\",\n",
      "        \"plan\": [\n",
      "            \"Search for the current weather in New York.\",\n",
      "            \"Write a weather report based on the information gathered.\"\n",
      "        ],\n",
      "        \"criticism\": \"None\",\n",
      "        \"speak\": \"I will search for the current weather in New York to create a weather report.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"search\",\n",
      "        \"args\": {\n",
      "            \"tool_input\": \"current weather in New York\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "System: Command search returned: {'type': 'weather_result', 'temperature': '59', 'unit': 'Fahrenheit', 'precipitation': '0%', 'humidity': '44%', 'wind': '7 mph', 'location': 'New York, NY', 'date': 'Saturday 11:00 AM', 'weather': 'Mostly sunny'}\n",
      "Human: Determine which next command to use, and respond using the format specified above:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"I have gathered the current weather information for New York. Now, I should proceed to write the weather report based on the details I found.\",\n",
      "        \"reasoning\": \"Writing the weather report will provide a summary of the current conditions in New York.\",\n",
      "        \"plan\": [\n",
      "            \"Compose a weather report for New York based on the gathered information.\"\n",
      "        ],\n",
      "        \"criticism\": \"None\",\n",
      "        \"speak\": \"I will now write a weather report for New York based on the current conditions.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"write_file\",\n",
      "        \"args\": {\n",
      "            \"file_path\": \"weather_report_new_york.txt\",\n",
      "            \"text\": \"Weather Report for New York:\\n\\n- Location: New York, NY\\n- Date: Saturday 11:00 AM\\n- Temperature: 59°F\\n- Weather: Mostly sunny\\n- Precipitation: 0%\\n- Humidity: 44%\\n- Wind: 7 mph\",\n",
      "            \"append\": false\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Tom, Assistant\n",
      "Your decisions must always be made independently without seeking user assistance.\n",
      "Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
      "If you have completed all your tasks, make sure to use the \"finish\" command.\n",
      "\n",
      "GOALS:\n",
      "\n",
      "1. write a weather report for New york today\n",
      "\n",
      "\n",
      "Constraints:\n",
      "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
      "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
      "3. No user assistance\n",
      "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
      "\n",
      "Commands:\n",
      "1. search: useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"tool_input\": {\"type\": \"string\"}}\n",
      "2. write_file: Write file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}, \"append\": {\"title\": \"Append\", \"description\": \"Whether to append to an existing file.\", \"default\": false, \"type\": \"boolean\"}}\n",
      "3. read_file: Read file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
      "4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
      "\n",
      "Resources:\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Term memory management.\n",
      "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
      "4. File output.\n",
      "\n",
      "Performance Evaluation:\n",
      "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
      "2. Constructively self-criticize your big-picture behavior constantly.\n",
      "3. Reflect on past decisions and strategies to refine your approach.\n",
      "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
      "\n",
      "You should only respond in JSON format as described below \n",
      "Response Format: \n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"thought\",\n",
      "        \"reasoning\": \"reasoning\",\n",
      "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
      "        \"criticism\": \"constructive self-criticism\",\n",
      "        \"speak\": \"thoughts summary to say to user\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"command name\",\n",
      "        \"args\": {\n",
      "            \"arg name\": \"value\"\n",
      "        }\n",
      "    }\n",
      "} \n",
      "Ensure the response can be parsed by Python json.loads\n",
      "System: The current time and date is Sat May 11 20:32:17 2024\n",
      "System: This reminds you of these events from your past:\n",
      "['Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I need to start by writing a weather report for New York today. I should search for the current weather information to include in the report.\",\\n        \"reasoning\": \"By searching for the current weather information, I can provide an accurate report for New York.\",\\n        \"plan\": [\\n            \"Search for the current weather in New York.\",\\n            \"Write a weather report based on the information gathered.\"\\n        ],\\n        \"criticism\": \"None\",\\n        \"speak\": \"I will search for the current weather in New York to create a weather report.\"\\n    },\\n    \"command\": {\\n        \"name\": \"search\",\\n        \"args\": {\\n            \"tool_input\": \"current weather in New York\"\\n        }\\n    }\\n} \\nResult: Command search returned: {\\'type\\': \\'weather_result\\', \\'temperature\\': \\'59\\', \\'unit\\': \\'Fahrenheit\\', \\'precipitation\\': \\'0%\\', \\'humidity\\': \\'44%\\', \\'wind\\': \\'7 mph\\', \\'location\\': \\'New York, NY\\', \\'date\\': \\'Saturday 11:00 AM\\', \\'weather\\': \\'Mostly sunny\\'} ', 'Assistant Reply: {\\n    \"thoughts\": {\\n        \"text\": \"I have gathered the current weather information for New York. Now, I should proceed to write the weather report based on the details I found.\",\\n        \"reasoning\": \"Writing the weather report will provide a summary of the current conditions in New York.\",\\n        \"plan\": [\\n            \"Compose a weather report for New York based on the gathered information.\"\\n        ],\\n        \"criticism\": \"None\",\\n        \"speak\": \"I will now write a weather report for New York based on the current conditions.\"\\n    },\\n    \"command\": {\\n        \"name\": \"write_file\",\\n        \"args\": {\\n            \"file_path\": \"weather_report_new_york.txt\",\\n            \"text\": \"Weather Report for New York:\\\\n\\\\n- Location: New York, NY\\\\n- Date: Saturday 11:00 AM\\\\n- Temperature: 59°F\\\\n- Weather: Mostly sunny\\\\n- Precipitation: 0%\\\\n- Humidity: 44%\\\\n- Wind: 7 mph\",\\n            \"append\": false\\n        }\\n    }\\n} \\nResult: Command write_file returned: File written successfully to weather_report_new_york.txt. ']\n",
      "\n",
      "\n",
      "Human: Determine which next command to use, and respond using the format specified above:\n",
      "AI: {\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"I need to start by writing a weather report for New York today. I should search for the current weather information to include in the report.\",\n",
      "        \"reasoning\": \"By searching for the current weather information, I can provide an accurate report for New York.\",\n",
      "        \"plan\": [\n",
      "            \"Search for the current weather in New York.\",\n",
      "            \"Write a weather report based on the information gathered.\"\n",
      "        ],\n",
      "        \"criticism\": \"None\",\n",
      "        \"speak\": \"I will search for the current weather in New York to create a weather report.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"search\",\n",
      "        \"args\": {\n",
      "            \"tool_input\": \"current weather in New York\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "System: Command search returned: {'type': 'weather_result', 'temperature': '59', 'unit': 'Fahrenheit', 'precipitation': '0%', 'humidity': '44%', 'wind': '7 mph', 'location': 'New York, NY', 'date': 'Saturday 11:00 AM', 'weather': 'Mostly sunny'}\n",
      "Human: Determine which next command to use, and respond using the format specified above:\n",
      "AI: {\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"I have gathered the current weather information for New York. Now, I should proceed to write the weather report based on the details I found.\",\n",
      "        \"reasoning\": \"Writing the weather report will provide a summary of the current conditions in New York.\",\n",
      "        \"plan\": [\n",
      "            \"Compose a weather report for New York based on the gathered information.\"\n",
      "        ],\n",
      "        \"criticism\": \"None\",\n",
      "        \"speak\": \"I will now write a weather report for New York based on the current conditions.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"write_file\",\n",
      "        \"args\": {\n",
      "            \"file_path\": \"weather_report_new_york.txt\",\n",
      "            \"text\": \"Weather Report for New York:\\n\\n- Location: New York, NY\\n- Date: Saturday 11:00 AM\\n- Temperature: 59°F\\n- Weather: Mostly sunny\\n- Precipitation: 0%\\n- Humidity: 44%\\n- Wind: 7 mph\",\n",
      "            \"append\": false\n",
      "        }\n",
      "    }\n",
      "}\n",
      "System: Command write_file returned: File written successfully to weather_report_new_york.txt.\n",
      "Human: Determine which next command to use, and respond using the format specified above:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"I have successfully written the weather report for New York. Since I have completed the task of writing the weather report, I should proceed to finish all objectives.\",\n",
      "        \"reasoning\": \"Completing the weather report marks the completion of the assigned tasks for now.\",\n",
      "        \"plan\": [\n",
      "            \"Use the 'finish' command to signal the completion of all objectives.\"\n",
      "        ],\n",
      "        \"criticism\": \"None\",\n",
      "        \"speak\": \"I will now finish all objectives as I have completed writing the weather report for New York.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"finish\",\n",
      "        \"args\": {\n",
      "            \"response\": \"Weather report for New York has been successfully written and all objectives have been completed.\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Weather report for New York has been successfully written and all objectives have been completed.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run([\"write a weather report for New york today\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
